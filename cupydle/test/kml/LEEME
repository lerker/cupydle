
AUDIO
=====

El Objetivo de este conjunto de scripts es extraer caracteristicas del audio de cada video. Ya que la dimension es muy alta (tasa de muestreo de 44100 bit/s) para el archivo de audio ya cortado donde interesa, entonces lo que se desea es estraer componentes caracteristicas de cada archivo y guardarlas en un formato manejable.

Se requieren algunos scripts que se integran a matlab, desde los siguientes repositorios:

-> http://labrosa.ee.columbia.edu/matlab/audioread/
-> http://www.ee.ic.ac.uk/hp/staff/dmb/voicebox/voicebox.html

Orden de ejecucion:
-------------------

./extractorWav.py
./extractorAudioRaw.sh


Descripcion de los scripts:
---------------------------

./extractorWav.py
    A partir de la pista de audio .wav se corta la misma en referencia a los frames de inicio y fin del video de procedencia de dicha pista.
    El frame rate de los videos es de 30 f/s. El retorno es un archivo .csv en el cual se encuentra todos los valores del archivo.wav cortado en una sola linea.
    Argumentos:
        [0] nombreArchivo.wav
        [1] frameInicial
        [2] frameFinal
    Retorno:
        nombreArchivo-audio_cropRaw.csv en el cual se encuentra los valores de la pista de audio recortada en una sola columna

./extractorAudioRaw.sh
    Dicho script busca en el directorio las pistas de audio (../an1.wav) y los archivos correspondientes a cada una donde estan los frames de inicio y fin (an1-voiced_frames.txt) para cada pista. Aplica el script 'extratorWav.py' con el nombre del archivo y sus frames de inicio y final respectivamente a cada uno.
    Argumentos:
        NULL
    Restorno:
        archivos individuales .csv correspodientes a cada pista de audio

::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

VIDEO
=====

El objetivo es extraer del video factores caracteristicos que se relacionan con una emocion humana, como ser una mueca o sonriasa...
Se extrae de cada video la zona de los ojos y boca donde el hablante emite algun sonido. Con ello contamos con el archivo 'crudo' de datos. Otro proceso es reducir la dimensionalidad anterior (230300 -> X < 150) gracias a tecnicas como PCA.

Orden de ejecucion:
-------------------

./extract_voiced_frames.sh
./prom_voiced_frames.sh
./extract_video_features.sh

./concatenarVideos.sh
./pca.py all_videos_features_clases[shuffled].csv 70 all_videos_pca_70.npz
./preprocesamiento.py all_videos_pca_70.npz "coso_procesado" 'z_score+min_max'


Descripcion de los scripts:
---------------------------

./extract_voiced_frames.sh
    Determina donde comienza y termina el frame de voz en el video.

./prom_voiced_frames.sh
    Promedia de todos los videos, cuantos frames son de voz.

./extract_video_features.sh
    Llama a ./VideoFeaturesExtraction el cual manda el archivo de video a procesar.
    Recibe la ruta de un archivo de video .avi. Este programa se encarga de guardar en un archivo "-video_features.csv" 4900 valores (70*35 * 2(zona ojos y boca)) por frame relevante. En este trabajo se determino un promedio de 47 frames relevantes para toda la base de datos. Para determinar este promedio se utilizo el script "prom_voiced_frames.sh"

./concatenarVideos.sh <archivoSalida.csv>
    Busca en el directorio (y subdirectorios) todos los archivos con el patron '*video_features.csv' el cual contiene todas la caracteristicas que fueron estraidas previamente. (4900 valores) por frames (47)
    Cada uno de estos archivos son la concatenacion de los frames caracteristicos de los videos ya procesados de su directorio.
    Argumentos:
        [0] nombreArchivoSalida.csv donde de almacena el archivo resultalte
    Retorno:
        Archivo del tipo 'csv' el cual contine por cada fila un ejemplo. Cada uno al inicio contiene la etiqueta (6) caracteristica de la emocion (1,2...6). El archivo resultante es de 720x230300
    Junta todo el contenido en un unico archivo, por linea se corresponde a un ejemplo (720x230300)
    >>> ./concatenarVideos.sh all_videos_features_clases.csv

./pca.py <archivo_entrada> <#componentes> <archivo_salida>
    Calcula PCA para cada grupo de emociones (6).Por defecto se utilizaron 70 componentes principales.
    Argumentos:
        [0] archivoEntrada[.csv][.npz]
        [1] # de componentes de la proyeccion pca
        [2] archivoSalida, se le concatena .npz (comprimido de numpy)
    Retorno:
        Archivo comprimido de NUMPY, .npz. Se lee como diccionario donde las keys son 'videos' y 'clases' para los videos y las clases respectivamente.
    >>> python3 pca.py all_videos_features_clases_shuffled.csv 70 videos_pca_70_features_raw
    >>> python3 pca.py all_videos_features_clases_shuffled.csv 85 videos_pca_85_features_raw


./preprocesamiento.py <archivoEntrada> <archivoSalida> <proceso>
    Recibe el archivo y lo procesa con algunos de los normalizadores predefinidos ('min_max_escalado', 'z_score', 'blanqueo', 'z_score+min_max')
    Argum
    retorna un archivo numpy.narray comprimido en un tipo .npz
    argumentos:
        [0] archivoCrudo.csv
        [1] archivoSalida
        [2] tipoProceso
    >>> python3 preprocesamiento.py all_videos_features_clases.npz "coso_procesado" 'z_score+min_max'
    >>> python3 preprocesamiento.py videos_pca_85_features_raw.npz videos_pca_85_features_procesado_minmax "min_max"


::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

MLP
===

./cupydle/test/mlp_FACE.py <-d> <--dataset> <-l> <-b> <-e>
    ejecuta el main loop para el entrenamiento del dataset especifico para el conjunto de datos de emociones
    -d directorio donde se alamcenan los datos generados
    --dataset conjunto de datos especificos
    -l capas que componen al mlp
    -b batchsize
    -e numero de epocas

    >>> python3 cupydle/test/mlp_FACE.py -d test_MLP -l 230300 1000 500 6 -e 500

unir simplemente dos archivos en uno y delimitados por ,

>>> paste -d, coso1.csv coso2.csv

# concatenar dos archivos .csv donde los dos tienen la primer columna como label (que se corresponden uno a uno si o si!!!) en uno solo, donde la primer columna es el label y a continuacion el archivo 1 y luego el dos todo seguido de comas


>>> cut -d',' -f2-  coso2.csv | paste -d, coso1.csv -

# la salida de coso2 se une con coso1 a la cual coso2 se le fue extraido su primer columna


